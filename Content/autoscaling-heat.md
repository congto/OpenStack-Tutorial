###Scale an application with Heat
The Heat orchestration service can help with one of the most important topics in cloud computing: scalability. When a cloud application suffers for heavy load, there are two ways to scale:

1. **Vertical Scale.** This is the most obvious solution: when the server resources are not enough, use a more powerful server. Vertical scaling resizes the compute instance to a larger flavor, so that it gets more CPUs, more RAM and more disk space. This type of scaling works well up to a point. Once the maximum supported number of CPUs, RAM and disk space that an instance can have, there are no way to scale more. If the load generated by users continues to grow beyond that, we need to find a different way to scale.

2. **Horizontal Scale.** The other approach to scalability is to have the application running on a cluster of multiple servers. When an application runs on two or more instances, a load balancer is required to distributes client requests among servers. In this way, the application will be able to handle much larger volumes of clients. With this type of scaling, it is going to take longer to reach limits, since we continue to add servers behind the load balancer until we exhaust compute resources in the cloud. 

In this section, we are going to deploy an horizontal scaling stack by mean of Heat templates. Just to keep things simple, we are going to scale a simple web server providing a static page. We'll use two approach: manual scale and automatic scale (autoscaling).

####Manual Horizontal Scaling
Manual scaling requires the user scales the cluster manually when the load from clients reach the cluster limits. We start by writing a simple Heat template to deploy an Apache webserver on Ubuntu. The most clever part of the template is installing Apache in Ubuntu and customize the home page with the IP address of the server. Connecting to the Apache through the load balancer and refreshing the home page should show a changing IP address, because each time the page will be handled by a different server. We use the *cloudinit* capability to run an user data script at time of the instance start.

Here the snippet of ``apache.yaml`` template:
```
resources:
  webserver:
    type: OS::Nova::Server
    properties:
      image: { get_param: image }
      key_name: { get_param: key }
      flavor: { get_param: flavor }
      networks:
        - network: { get_param: private_network }
      user_data: |
        #!/bin/bash
        apt-get install apache2 -y
        echo "Hello "$(hostname -I)" !" > /var/www/html/index.html
```

Then we write a main template creates multiple identical copies of the server. This Heat template is based on a resource type called ``OS::Heat::ResourceGroup``. This resource wraps a standard resource definition and creates multiple identical copies of the resource.

Here the core snippet of ``cluster-heat-stack.yaml`` template:
```
parameters:
  cluster_size:
    type: number
    label: Cluster size
    description: Number of webserver instances in the cluster.
    default: 2

resources:
  cluster:
    type: OS::Heat::ResourceGroup
    properties:
      count: { get_param: cluster_size }
      resource_def:
        type: ./apache.yaml
        properties:
          image: ubuntu
          flavor: small
          key: demokey
          private_network: { get_param: private_network }
```

The ``count`` property defines how many copies of the application to start. We set this value from a parameter ``cluster_size``, which the user can set. The ``resource_def`` property is where the resource that is getting scaled is configured.

Once we have the application running on multiple instances, we need for a load balancer that presents itself as the entry point to clients. The load balancer will accept the requests from clients and internally dispatch them to the actual servers.



####Automatic Horizontal Scaling
